{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "# Feel free to include your text patterns functions\n",
    "#from text_functions_solutions import clean_tokenize, get_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(\"convention_speeches.db\")\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to: convention_speeches.db\n",
      "Tables: []\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import os\n",
    "import sqlite3\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "import nltk\n",
    "from string import punctuation\n",
    "\n",
    "\n",
    "# Reproducibility\n",
    "random.seed(509)\n",
    "np.random.seed(509)\n",
    "\n",
    "try:\n",
    "    nltk.data.find(\"tokenizers/punkt\")\n",
    "except LookupError:\n",
    "    nltk.download(\"punkt\")\n",
    "\n",
    "try:\n",
    "    nltk.data.find(\"corpora/stopwords\")\n",
    "except LookupError:\n",
    "    nltk.download(\"stopwords\")\n",
    "\n",
    "# Open the conventions DB \n",
    "db_candidates = [\"convention_speeches.db\", \"2020_Conventions.db\"]\n",
    "db_path = next((p for p in db_candidates if os.path.exists(p)), None)\n",
    "if db_path is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not find convention DB. Put 'convention_speeches.db' or \"\n",
    "        \"'2020_Conventions.db' in the current folder.\"\n",
    "    )\n",
    "\n",
    "convention_db = sqlite3.connect(db_path)\n",
    "convention_cur = convention_db.cursor()\n",
    "\n",
    "# Quick sanity check\n",
    "try:\n",
    "    \n",
    "    convention_cur.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "    print(\"Connected to:\", db_path)\n",
    "    print(\"Tables:\", [t[0] for t in convention_cur.fetchall()])\n",
    "except Exception as e:\n",
    "    print(\"Connected, but couldnâ€™t list tables:\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" exercise. First, we'll pull in the text \n",
    "for each party and prepare it for use in Naive Bayes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conventions DB tables: ['conventions']\n",
      "Congressional DB tables: ['websites', 'candidate_data', 'tweets']\n"
     ]
    }
   ],
   "source": [
    "import os, sqlite3\n",
    "\n",
    "# paths\n",
    "CONV_DB_PATH = \"2020_Conventions.db\"      \n",
    "CONG_DB_PATH = \"congressional_data.db\"    \n",
    "\n",
    "assert os.path.exists(CONV_DB_PATH), f\"Missing {CONV_DB_PATH}\"\n",
    "assert os.path.exists(CONG_DB_PATH), f\"Missing {CONG_DB_PATH}\"\n",
    "\n",
    "# open convention DB\n",
    "conv_db = sqlite3.connect(CONV_DB_PATH)\n",
    "conv_cur = conv_db.cursor()\n",
    "\n",
    "# open congressional DB\n",
    "cong_db = sqlite3.connect(CONG_DB_PATH)\n",
    "cong_cur = cong_db.cursor()\n",
    "\n",
    "def list_tables(cur):\n",
    "    cur.execute(\"SELECT name FROM sqlite_master WHERE type='table'\")\n",
    "    return [t[0] for t in cur.fetchall()]\n",
    "\n",
    "print(\"Conventions DB tables:\", list_tables(conv_cur))\n",
    "print(\"Congressional DB tables:\", list_tables(cong_cur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('conventions', 'table', 'CREATE TABLE conventions (\\n    party TEXT, \\n    night INTEGER, \\n    speaker TEXT,\\n    speaker_count INTEGER,\\n    time TEXT, \\n    text TEXT,\\n    text_len TEXT, \\n    file TEXT)')\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "\n",
    "# Reopen the convention DB\n",
    "conv_db = sqlite3.connect(CONV_DB_PATH)\n",
    "convention_cur = conv_db.cursor()\n",
    "\n",
    "# Show tables \n",
    "convention_cur.execute(\"SELECT name, type, sql FROM sqlite_master\")\n",
    "for row in convention_cur.fetchall():\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2541 speeches\n",
      "[['Skip to content The Company Careers Press Freelancers Blog Ã— Services Transcription Captions Foreign Subtitles Translation Freelancers About Contact Login Â« Return to Transcript Library home  Transcript Categories  All Transcripts 2020 Election Transcripts Classic Speech Transcripts Congressional Testimony & Hearing Transcripts Debate Transcripts Donald Trump Transcripts Entertainment Transcripts Financial Transcripts Interview Transcripts Political Transcripts Press Conference Transcripts Speech Transcripts Sports Transcripts Technology Transcripts Aug 21, 2020 2020 Democratic National Convention (DNC) Night 4 Transcript Rev  â€º  Blog  â€º  Transcripts  â€º 2020 Election Transcripts  â€º  2020 Democratic National Convention (DNC) Night 4 Transcript Night 4 of the 2020 Democratic National Convention (DNC) on August 20. Read the full transcript of the event here. Transcribe Your Own Content  Try Rev for free  and save time transcribing, captioning, and subtitling.', 'Democratic'], ['Iâ€™m here by calling the full session of the 48th Quadrennial National Convention of the Democratic Party to order. Welcome all to our final session of this historic and memorable convention. Weâ€™ve called the 48th Quadrennial Democratic National Convention to order.', 'Democratic']]\n"
     ]
    }
   ],
   "source": [
    "convention_data = []\n",
    "\n",
    "query_results = convention_cur.execute(\n",
    "    \"\"\"\n",
    "    SELECT text, party\n",
    "    FROM conventions\n",
    "    WHERE party != 'Other'\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "for row in query_results:\n",
    "    speech, party = row\n",
    "    convention_data.append([speech, party])\n",
    "\n",
    "print(f\"Loaded {len(convention_data)} speeches\")\n",
    "print(convention_data[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's a best practice to close up your DB connection when you're done\n",
    "convention_db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Giving up on the Affordable Care Act would have meant leaving 20 million without coverage out in the cold. But Joe Biden wasnâ€™t about to give up, because he knew what it was like to stand in their shoes. He was sworn into the Senate next to a hospital bed. His wife and daughter had been killed in a car crash. And lying in that bed were his two sons. 40 years later, one of those little boys, his son, Beau was diagnosed with cancer, and given only months to live. Itâ€™s hard to imagine a greater grief than losing your child. But Joe always knew that his family was one of the lucky ones. After that accident, his son got 40 more years of life, all because he had healthcare.',\n",
       "  'Democratic'],\n",
       " ['And focuses on protecting our children.', 'Democratic'],\n",
       " ['We will rescue kids from failing schools by helping their parents send them to a safe school of their choice. We will completely rebuild our depleted military. The countries that we are protecting at a massive cost to us will be asked to pay their fair share. We will take care of our great veterans like they have never been taken care of before.',\n",
       "  'Republican'],\n",
       " ['While heâ€™s no longer with us, Beau inspires me every day. Beau served our nation in uniform. A year in Iraq, a decorated Iraqi war veteran. So I take very personally the profound responsibility of serving as commander in chief.',\n",
       "  'Democratic'],\n",
       " ['How do we know.', 'Democratic']]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'll be useful for us to have a large sample size than 2024 affords, since those speeches tend to be long and contiguous. Let's make a new list-of-lists called `conv_sent_data`. Instead of each first entry in the sublists being an entire speech, make each first entry just a sentence from the speech. Feel free to use NLTK's `sent_tokenize` [function](https://www.nltk.org/api/nltk.tokenize.sent_tokenize.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tanya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\tanya\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10740 sentences\n",
      "[['Skip to content The Company Careers Press Freelancers Blog Ã— Services Transcription Captions Foreign Subtitles Translation Freelancers About Contact Login Â« Return to Transcript Library home  Transcript Categories  All Transcripts 2020 Election Transcripts Classic Speech Transcripts Congressional Testimony & Hearing Transcripts Debate Transcripts Donald Trump Transcripts Entertainment Transcripts Financial Transcripts Interview Transcripts Political Transcripts Press Conference Transcripts Speech Transcripts Sports Transcripts Technology Transcripts Aug 21, 2020 2020 Democratic National Convention (DNC) Night 4 Transcript Rev  â€º  Blog  â€º  Transcripts  â€º 2020 Election Transcripts  â€º  2020 Democratic National Convention (DNC) Night 4 Transcript Night 4 of the 2020 Democratic National Convention (DNC) on August 20.', 'Democratic'], ['Read the full transcript of the event here.', 'Democratic'], ['Transcribe Your Own Content  Try Rev for free  and save time transcribing, captioning, and subtitling.', 'Democratic'], ['Iâ€™m here by calling the full session of the 48th Quadrennial National Convention of the Democratic Party to order.', 'Democratic'], ['Welcome all to our final session of this historic and memorable convention.', 'Democratic']]\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "conv_sent_data = []\n",
    "\n",
    "for speech, party in convention_data:\n",
    "    # Break each speech into sentences\n",
    "    sentences = sent_tokenize(speech)\n",
    "    for sent in sentences:\n",
    "        conv_sent_data.append([sent, party])\n",
    "\n",
    "print(f\"Loaded {len(conv_sent_data)} sentences\")\n",
    "print(conv_sent_data[:5])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's look at some random entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['90% of Americans support common sense gun laws, because we need to do more to address the epidemic of gun violence.',\n",
       "  'Democratic'],\n",
       " ['This what our President Donald Trump did for me, and for that, I will be forever grateful.',\n",
       "  'Republican'],\n",
       " ['So what did you think about Kamala Harrisâ€™s speech last night.',\n",
       "  'Democratic'],\n",
       " ['In America, we have not yet experienced physical persecution, even though the left has tried to silence us.',\n",
       "  'Republican'],\n",
       " ['That same night, Donald Trump came to the hospital along with first lady, Melania Trump.',\n",
       "  'Republican']]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(conv_sent_data,k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for our final cleaning before modeling. Go through `conv_sent_data` and take the following steps: \n",
    "\n",
    "1. Tokenize on whitespace\n",
    "1. Remove punctuation\n",
    "1. Remove tokens that fail the `isalpha` test\n",
    "1. Remove stopwords\n",
    "1. Casefold to lowercase\n",
    "1. Join the remaining tokens into a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['he',\n",
       "   'faced',\n",
       "   'wars',\n",
       "   'without',\n",
       "   'end',\n",
       "   'in',\n",
       "   'sight',\n",
       "   'creation',\n",
       "   'of',\n",
       "   'failed',\n",
       "   'states',\n",
       "   'like',\n",
       "   'libya',\n",
       "   'and',\n",
       "   'syria',\n",
       "   'a',\n",
       "   'pass',\n",
       "   'that',\n",
       "   'allowed',\n",
       "   'a',\n",
       "   'terrorist',\n",
       "   'caliphate',\n",
       "   'to',\n",
       "   'grow',\n",
       "   'and',\n",
       "   'leadership',\n",
       "   'in',\n",
       "   'washington',\n",
       "   'that',\n",
       "   'allowed',\n",
       "   'our',\n",
       "   'military',\n",
       "   'to',\n",
       "   'atrophy',\n",
       "   'while',\n",
       "   'we',\n",
       "   'spent',\n",
       "   'trillions',\n",
       "   'of',\n",
       "   'dollars',\n",
       "   'abroad',\n",
       "   'instead',\n",
       "   'of',\n",
       "   'investing',\n",
       "   'at',\n",
       "   'home'],\n",
       "  'Republican'),\n",
       " (['joe',\n",
       "   'biden',\n",
       "   'said',\n",
       "   'black',\n",
       "   'people',\n",
       "   'are',\n",
       "   'a',\n",
       "   'monolithic',\n",
       "   'community'],\n",
       "  'Republican'),\n",
       " (['well',\n",
       "   'iâ€™m',\n",
       "   'glad',\n",
       "   'to',\n",
       "   'hear',\n",
       "   'it',\n",
       "   'but',\n",
       "   'boy',\n",
       "   'i',\n",
       "   'think',\n",
       "   'a',\n",
       "   'lot',\n",
       "   'of',\n",
       "   'americans',\n",
       "   'are',\n",
       "   'going',\n",
       "   'to',\n",
       "   'be',\n",
       "   'dealing',\n",
       "   'with',\n",
       "   'that',\n",
       "   'for',\n",
       "   'a',\n",
       "   'long',\n",
       "   'time'],\n",
       "  'Democratic'),\n",
       " (['god',\n",
       "   'bless',\n",
       "   'you',\n",
       "   'and',\n",
       "   'god',\n",
       "   'bless',\n",
       "   'the',\n",
       "   'united',\n",
       "   'states',\n",
       "   'of',\n",
       "   'america'],\n",
       "  'Republican'),\n",
       " (['he',\n",
       "   'certainly',\n",
       "   'kept',\n",
       "   'things',\n",
       "   'interesting',\n",
       "   'but',\n",
       "   'more',\n",
       "   'importantly',\n",
       "   'president',\n",
       "   'donald',\n",
       "   'trump',\n",
       "   'has',\n",
       "   'kept',\n",
       "   'his',\n",
       "   'word',\n",
       "   'to',\n",
       "   'the',\n",
       "   'american',\n",
       "   'people'],\n",
       "  'Republican')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from string import punctuation\n",
    "\n",
    "clean_conv_sent_data = []  \n",
    "\n",
    "for idx, (sentence, party) in enumerate(conv_sent_data):\n",
    "    # lowercase\n",
    "    sent = sentence.lower()\n",
    "    \n",
    "    # remove punctuation \n",
    "    sent = re.sub(f\"[{re.escape(punctuation)}]\", \"\", sent)\n",
    "    \n",
    "    # split on whitespace into tokens\n",
    "    tokens = sent.split()\n",
    "    \n",
    "    # save cleaned sentence tokens with party\n",
    "    clean_conv_sent_data.append((tokens, party))\n",
    "\n",
    "# samples\n",
    "random.choices(clean_conv_sent_data, k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, let's make our function to turn these into features. First we need to build our list of candidate words. I started my exploration at a cutoff of 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2514 features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "# Flatten all tokens from clean_conv_sent_data\n",
    "tokens = [w for t, p in clean_conv_sent_data for w in t]\n",
    "\n",
    "# Build frequency distribution\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "# Collect words above cutoff\n",
    "feature_words = set(word for word, count in word_dist.items() if count > word_cutoff)\n",
    "\n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_conv_sent_data size: 10740\n",
      "sample: [(['skip', 'to', 'content', 'the', 'company', 'careers', 'press', 'freelancers', 'blog', 'Ã—', 'services', 'transcription', 'captions', 'foreign', 'subtitles', 'translation', 'freelancers', 'about', 'contact', 'login', 'Â«', 'return', 'to', 'transcript', 'library', 'home', 'transcript', 'categories', 'all', 'transcripts', '2020', 'election', 'transcripts', 'classic', 'speech', 'transcripts', 'congressional', 'testimony', 'hearing', 'transcripts', 'debate', 'transcripts', 'donald', 'trump', 'transcripts', 'entertainment', 'transcripts', 'financial', 'transcripts', 'interview', 'transcripts', 'political', 'transcripts', 'press', 'conference', 'transcripts', 'speech', 'transcripts', 'sports', 'transcripts', 'technology', 'transcripts', 'aug', '21', '2020', '2020', 'democratic', 'national', 'convention', 'dnc', 'night', '4', 'transcript', 'rev', 'â€º', 'blog', 'â€º', 'transcripts', 'â€º', '2020', 'election', 'transcripts', 'â€º', '2020', 'democratic', 'national', 'convention', 'dnc', 'night', '4', 'transcript', 'night', '4', 'of', 'the', '2020', 'democratic', 'national', 'convention', 'dnc', 'on', 'august', '20'], 'Democratic'), (['read', 'the', 'full', 'transcript', 'of', 'the', 'event', 'here'], 'Democratic')]\n",
      "With a word cutoff of 5, we have 2891 features in the model.\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "print(\"clean_conv_sent_data size:\", len(clean_conv_sent_data))\n",
    "print(\"sample:\", clean_conv_sent_data[:2])\n",
    "\n",
    " Build feature_words from the cleaned tokenized sentences\n",
    "import nltk\n",
    "\n",
    "word_cutoff = 5 \n",
    "tokens = [w for t, _ in clean_conv_sent_data for w in t]  \n",
    "fd = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = {w for w, c in fd.items() if c >= word_cutoff}\n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of feature sets: 10740\n",
      "Example: ({'skip': True, 'to': True, 'content': True, 'the': True, 'company': True, 'careers': True, 'press': True, 'freelancers': True, 'blog': True, 'Ã—': True, 'services': True, 'transcription': True, 'captions': True, 'foreign': True, 'subtitles': True, 'translation': True, 'about': True, 'contact': True, 'login': True, 'Â«': True, 'return': True, 'transcript': True, 'library': True, 'home': True, 'categories': True, 'all': True, 'transcripts': True, '2020': True, 'election': True, 'classic': True, 'speech': True, 'congressional': True, 'testimony': True, 'hearing': True, 'debate': True, 'donald': True, 'trump': True, 'entertainment': True, 'financial': True, 'interview': True, 'political': True, 'conference': True, 'sports': True, 'technology': True, 'aug': True, '21': True, 'democratic': True, 'national': True, 'convention': True, 'dnc': True, 'night': True, '4': True, 'rev': True, 'â€º': True, 'of': True, 'on': True, 'august': True, '20': True}, 'Democratic')\n"
     ]
    }
   ],
   "source": [
    "# Turn sentences into feature dictionaries\n",
    "feature_sets = [\n",
    "    (conv_features(\" \".join(tokens), feature_words), party)\n",
    "    for tokens, party in clean_conv_sent_data\n",
    "]\n",
    "\n",
    "print(\"Number of feature sets:\", len(feature_sets))\n",
    "print(\"Example:\", feature_sets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 8592, Test size: 2148\n"
     ]
    }
   ],
   "source": [
    "# Shuffle and split into train/test\n",
    "random.shuffle(feature_sets)\n",
    "\n",
    "train_size = int(len(feature_sets) * 0.8)  # 80% train, 20% test\n",
    "train_set, test_set = feature_sets[:train_size], feature_sets[train_size:]\n",
    "\n",
    "print(f\"Training size: {len(train_set)}, Test size: {len(test_set)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 0.7104283054003724\n",
      "Most Informative Features\n",
      "                   votes = True           Democr : Republ =     40.6 : 1.0\n",
      "                 radical = True           Republ : Democr =     30.4 : 1.0\n",
      "             enforcement = True           Republ : Democr =     22.7 : 1.0\n",
      "              affordable = True           Democr : Republ =     18.4 : 1.0\n",
      "                  racism = True           Democr : Republ =     17.0 : 1.0\n",
      "                   media = True           Republ : Democr =     15.6 : 1.0\n",
      "                    mike = True           Republ : Democr =     14.4 : 1.0\n",
      "                   lewis = True           Democr : Republ =     14.2 : 1.0\n",
      "                 climate = True           Democr : Republ =     14.1 : 1.0\n",
      "                freedoms = True           Republ : Democr =     13.1 : 1.0\n",
      "                 freedom = True           Republ : Democr =     13.0 : 1.0\n",
      "                    isis = True           Republ : Democr =     12.5 : 1.0\n",
      "                 destroy = True           Republ : Democr =     11.9 : 1.0\n",
      "                  kamala = True           Democr : Republ =     11.6 : 1.0\n",
      "                   china = True           Republ : Democr =     10.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "from nltk import NaiveBayesClassifier\n",
    "from nltk.classify import accuracy\n",
    "\n",
    "# Train\n",
    "classifier = NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Accuracy on test set:\", accuracy(classifier, test_set))\n",
    "\n",
    "# Show most informative features\n",
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Sanity checks passed!\n"
     ]
    }
   ],
   "source": [
    "result = conv_features(\"obama was the president\", feature_words)\n",
    "assert \"obama\" in result\n",
    "assert \"president\" in result\n",
    "\n",
    "result2 = conv_features(\"some people in america are citizens\", feature_words)\n",
    "assert all(w in result2 for w in [\"people\", \"america\", \"citizens\"])\n",
    "\n",
    "print(\"âœ… Sanity checks passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.438\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "             enforcement = True           Republ : Democr =     27.5 : 1.0\n",
      "                   votes = True           Democr : Republ =     21.6 : 1.0\n",
      "                 climate = True           Democr : Republ =     17.3 : 1.0\n",
      "                 destroy = True           Republ : Democr =     17.1 : 1.0\n",
      "                supports = True           Republ : Democr =     16.1 : 1.0\n",
      "                   media = True           Republ : Democr =     15.9 : 1.0\n",
      "                preserve = True           Republ : Democr =     15.1 : 1.0\n",
      "                  signed = True           Republ : Democr =     15.1 : 1.0\n",
      "              appreciate = True           Republ : Democr =     14.0 : 1.0\n",
      "                freedoms = True           Republ : Democr =     14.0 : 1.0\n",
      "                 private = True           Republ : Democr =     11.9 : 1.0\n",
      "                  defund = True           Republ : Democr =     10.9 : 1.0\n",
      "                    drug = True           Republ : Democr =     10.3 : 1.0\n",
      "                 special = True           Republ : Democr =     10.3 : 1.0\n",
      "                   trade = True           Republ : Democr =     10.0 : 1.0\n",
      "                everyday = True           Republ : Democr =      9.9 : 1.0\n",
      "                   local = True           Republ : Democr =      9.9 : 1.0\n",
      "                 allowed = True           Republ : Democr =      9.7 : 1.0\n",
      "                   elect = True           Democr : Republ =      9.6 : 1.0\n",
      "                   moved = True           Republ : Democr =      9.0 : 1.0\n",
      "                   bless = True           Republ : Democr =      9.0 : 1.0\n",
      "                    land = True           Republ : Democr =      8.9 : 1.0\n",
      "                  agenda = True           Republ : Democr =      8.8 : 1.0\n",
      "               countries = True           Republ : Democr =      8.8 : 1.0\n",
      "                   crime = True           Republ : Democr =      8.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a little prose here about what you see in the classifier. Anything odd or interesting?\n",
    "\n",
    "### My Observations\n",
    "\n",
    "_Your observations to come._\n",
    "\n",
    "The model found words that link to each partyâ€™s common topics. For example, â€œenforcementâ€ and â€œfreedomsâ€ show up more for Republicans, while â€œvotesâ€ and â€œclimateâ€ show up more for Democrats. That makes sense since each party tends to focus on different issues in their speeches. Whatâ€™s surprising is the low accuracy (about 44%), which is close to guessing. This probably means the sentences overlap a lot between parties, so the model has a hard time telling them apart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"congressional_twitter_data.db\")\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulled 664656 tweets\n",
      "[('Mo Brooks', 'Republican', b'\"Brooks Joins Alabama Delegation in Voting Against Flawed Funding Bill\" http://t.co/3CwjIWYsNq'), ('Mo Brooks', 'Republican', b'\"Brooks: Senate Democrats Allowing President to Give Americans\\xe2\\x80\\x99 Jobs to Illegals\" #securetheborder https://t.co/mZtEaX8xS6'), ('Mo Brooks', 'Republican', b'\"NASA on the Square\" event this Sat. 11AM \\xe2\\x80\\x93 4PM. Stop by &amp; hear about the incredible work done in #AL05! @DowntownHSV http://t.co/R9zY8WMEpA')]\n"
     ]
    }
   ],
   "source": [
    "# Connect to the congressional DB \n",
    "cong_db = sqlite3.connect(\"congressional_data.db\")\n",
    "cong_cur = cong_db.cursor()\n",
    "\n",
    "# Pull \n",
    "results = cong_cur.execute(\n",
    "    '''\n",
    "       SELECT DISTINCT \n",
    "              cd.candidate, \n",
    "              cd.party,\n",
    "              tw.tweet_text\n",
    "       FROM candidate_data cd \n",
    "       INNER JOIN tweets tw \n",
    "           ON cd.twitter_handle = tw.handle \n",
    "           AND cd.candidate == tw.candidate \n",
    "           AND cd.district == tw.district\n",
    "       WHERE cd.party in ('Republican','Democratic') \n",
    "         AND tw.tweet_text NOT LIKE '%RT%'\n",
    "    '''\n",
    ")\n",
    "\n",
    "# Convert to list \n",
    "results = list(results)\n",
    "\n",
    "print(f\"Pulled {len(results)} tweets\")\n",
    "print(results[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 664656 tweets\n",
      "[[b'\"Brooks Joins Alabama Delegation in Voting Against Flawed Funding Bill\" http://t.co/3CwjIWYsNq', 'Republican'], [b'\"Brooks: Senate Democrats Allowing President to Give Americans\\xe2\\x80\\x99 Jobs to Illegals\" #securetheborder https://t.co/mZtEaX8xS6', 'Republican'], [b'\"NASA on the Square\" event this Sat. 11AM \\xe2\\x80\\x93 4PM. Stop by &amp; hear about the incredible work done in #AL05! @DowntownHSV http://t.co/R9zY8WMEpA', 'Republican']]\n"
     ]
    }
   ],
   "source": [
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n",
    "\n",
    "tweet_data = []\n",
    "\n",
    "# Loop through results \n",
    "for candidate, party, tweet in results:\n",
    "    if tweet and party in (\"Republican\", \"Democratic\"):\n",
    "        tweet_data.append([tweet, party])\n",
    "\n",
    "print(f\"Loaded {len(tweet_data)} tweets\")\n",
    "print(tweet_data[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data,k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: Earlier today, I spoke on the House Floor abt protecting health care for women and praised @PPmarmonte for their work on the Central Coast. https://t.co/WqgTRzT7VV\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: Go Tribe! #RallyTogether https://t.co/0NXutFL9L5\n",
      "Actual party is Democratic and our classifier says Democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: Apparently, Trump thinks it's just too easy for students overwhelmed by the crushing burden of debt to pay off student loans #TrumpBudget https://t.co/ckYQO5T0Qh\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: Weâ€™re grateful for our first responders, our rescue personnel, our firefighters, our police, and volunteers who have been working tirelessly to keep people safe, provide much-needed help, while putting their own lives on the line.\n",
      "\n",
      "https://t.co/eZPv0vMIz3\n",
      "Actual party is Republican and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: Letâ€™s make it even Greater !! #KAG ðŸ‡ºðŸ‡¸ https://t.co/y9qoZD5L2z\n",
      "Actual party is Republican and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: We have about 1hr until the @cavs tie up the series 2-2. I'm #ALLin216 @RepBarbaraLee you scared? #roadtovictory\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: Congrats to @belliottsd on his new gig at SD City Hall. We are glad you will continue to serveâ€¦ https://t.co/fkvMw3cqdI\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: We are really close, we have over $3500 raised toward the match right now. Whoot!! (Thatâ€™s $7000 for the non-math majors in the room ðŸ˜‚). Help us get there https://t.co/Tu34C472sD https://t.co/QsdQkYpsmC\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: Today, the comment period for @POTUSâ€™s plan to expand offshore drilling opened to the public. You have 60 days (until March 9) to share why you oppose the proposed program directly with the Trump Administration. Comments can be made by email or mail. https://t.co/BaaYMeJxQn\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n",
      "Here's our (cleaned) tweet: Celebrated @ICSEastLAâ€™s 22 years of Eastside commitment &amp; saluted community leaders at last nightâ€™s awards dinner! https://t.co/7V7gH8giVB\n",
      "Actual party is Democratic and our classifier says Republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet, party in tweet_data_sample:\n",
    "    # Decode from bytes if needed\n",
    "    if isinstance(tweet, bytes):\n",
    "        tweet = tweet.decode(\"utf-8\", errors=\"ignore\")\n",
    "    \n",
    "    # Clean and tokenize the tweet\n",
    "    cleaned_tweet = \" \".join([w for w in tweet.lower().split()])\n",
    "    \n",
    "    # Extract features\n",
    "    features = conv_features(cleaned_tweet, feature_words)\n",
    "    \n",
    "    # Estimate party with classifier\n",
    "    estimated_party = classifier.classify(features)\n",
    "    \n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifier says {estimated_party}.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# dictionary of counts by actual party and estimated party\n",
    "parties = ['Republican', 'Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties:\n",
    "    for p1 in parties:\n",
    "        results[p][p1] = 0\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "for idx, tp in enumerate(tweet_data):\n",
    "    tweet, party = tp\n",
    "    \n",
    "    # Decode if tweet is bytes\n",
    "    if isinstance(tweet, bytes):\n",
    "        tweet = tweet.decode(\"utf-8\", errors=\"ignore\")\n",
    "    \n",
    "    # Clean tweet\n",
    "    cleaned_tweet = \" \".join([w for w in tweet.lower().split()])\n",
    "    \n",
    "    # Extract features\n",
    "    features = conv_features(cleaned_tweet, feature_words)\n",
    "    \n",
    "    # Classify\n",
    "    estimated_party = classifier.classify(features)\n",
    "    \n",
    "    # Store result\n",
    "    results[party][estimated_party] += 1\n",
    "    \n",
    "    if idx > num_to_score:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 4020, 'Democratic': 352}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 5162, 'Democratic': 468})})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "_Write a little about what you see in the results_ \n",
    "\n",
    "\n",
    "The results show that the model is really good at spotting Republican tweets, but it struggles with Democratic ones. Most Democratic tweets got labeled as Republican, which means the classifier is biased. This could be because of the way the data was split or the words that were picked as features. Overall, the model works okay for Republicans but not so much for Democrats, so it would need more balance to be useful."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
